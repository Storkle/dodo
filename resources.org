#+TITLE: Resources
#+Author: Seth Burleigh
#+Date: 
#+Options: toc:nil
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{subfigure}
#+LaTeX_CLASS: smarticle
#+LaTeX_HEADER: \usepackage{courier}
#+LaTeX_HEADER: \usepackage{libertine}
#+LaTeX_HEADER: \usepackage{sectsty}
#+LaTeX_HEADER: \sectionfont{\normalfont\scshape}
#+LaTeX_HEADER: \subsectionfont{\normalfont\itshape}
 
\newpage
\setcounter{tocdepth}{3}
\tableofcontents
\newpage

Giulio Tononi


[[http://videolectures.net/icml07_tenenbaum_bmhi/][tenebaum]]!!!!!!!
[[http://www.acceleratingfuture.com/michael/blog/2006/11/bitphase-moves-forward/][bitphase]]

Solomonoff induction

[[http://www.acceleratingfuture.com/michael/blog/category/ai/][accelerating future stuff]]

http://singularityhub.com/2011/02/03/will-vicarious-systems-silicon-valley-pedigree-help-it-build-agi/#more-26453

/Probability Theory: The Logic of Science/

Kolmogorov complexity
[[http://www.idsia.ch/~juergen/kolmogorov.html][generalize kolmogorov]]

starglider min-faq
http://bbs.stardestroyer.net/viewtopic.php?f=5&t=136633

* SL4 stuff
My biggest criticism of AI designs generally is that almost none of them really offer a 
theoretically solid reason why the design can be expected to produce AI in the first place. 
Engineering design based on things that "sound good" does not fly (no pun intended) in any 
other domain (except perhaps social engineering) and it has never produced good results 
anywhere it has been tried as a general rule. Justification and validation is a very necessary 
prerequisite that cannot be glossed over because it is difficult or inconvenient. 

> The problem is that AGI theories are very 
> hard to validate; to the untrained (or even moderately trained) 
> eye one looks as good as another. 
This is to be expected, since most of the people interested in validating an AGI theory are 
interested in exploiting it rather than understanding it. And of these people, the smart ones 
are rightly skeptical. Nothing beats a killer demo. 

One can burn a lot of resources on iterative verification by implementation. It will get the job 
done, but it ain't cheap. On the other hand, there are often subtle problems that you 
discover in implementation that would have taken a lot longer to discover doing high-level 
design. I wish I hadn't spent so much time on iterative implementation, but I'm not sure that 
I would have been obviously better off doing it another way. 

http://www.sl4.org/archive/0502/10741.html


I may be misunderstanding him, but I take him to mean not that that 
particular theory (collective volition) is the one true one, but 
that to be more useful than dangerous an AGI project must: 
1) Be based on some solid theory of Friendliness, 
2) Have a grave respect for the potential dangers and a strong 
safety-first attitude. 

http://www.sl4.org/archive/0502/10742.html

---------------
http://www.sl4.org/archive/0502/10743.html
All the major, credible AGI projects take care to examine the field 
of AI, looking for incremental successes to reuse and common pitfalls 
to avoid. I still regularly see people starting personal projects and 
declaring that 'since all past work failed, it must be irrelevant, so 
I don't need to pay much/any attention to it'. 

Most relevant recent theoretical progress has been in decision 
theory and cognitive science, not in AI as such; AGI projects don't 
often reuse technology from earlier, failed AGI projects (or from 
other people's AGI projects in general). 

> And this does not apply to the folks at SIAI because...? 
It does apply to the SIAI. Our only defence is that we acknowledge 
the depth of the self-delusion problem (and take what steps we can 
to detect it). In fact this is another reason I want to do (limited) 
prototyping now; if we have serious blind spots, I want to know about 
them ASAP. This is also a major reason for Eliezer's push for formally 
provable algorithms and techniques for FAI; while deluding yourself 
into thinking you have an AGI design when you don't is merely a waste 
of time and resources, deluding yourself into thinking you have an 
FAI design when you really only have a seed AI design is fatal. 

http://www.sl4.org/archive/0502/10749.html
more explanation of above.. on 'volatility' principle 
* More Random

http://www.physorg.com/news2933.html

Minsky notes that causality is often very tangled in agent interactions. While true this should probably be 
'considered harmful' judging by the number of AI researchers who think that establishing tangled networks of 
arbitrary agents ('bubbling stews') driven by a few goal seeking dynamics is sufficient for cognition. 



[[http://www.sl4.org/archive/0502/10740.html][AGI prototype]]

[[http://yudkowsky.net/rational/bayes][Bayes theorem]]
[[http://yudkowsky.net/rational/cognitive-biases][Heuristics and biases section]]
[[http://bayes.wustl.edu/etj/science.pdf.html][Bayes in science and engineering]]

I need genetic algorithm introduction!
[[http://yudkowsky.net/rational][yudowsky]]

[[http://lesswrong.com/][Rationality]]

* FAILURES
  
http://www.acceleratingfuture.com/michael/blog/2006/11/michael-wilson-on-ways-of-looking-at-ai/

starglider (not faiure!): good summaries: 

http://www.acceleratingfuture.com/wiki/Starglider/The_Failure_Of_GOFAI

* Random
[[http://people.cs.kuleuven.be/~joaquin.vanschoren/zsp/fluidconcepts/node27.html][WRITING CODELETS]]

Bayesian reasoning.

[[http://www.acceleratingfuture.com/wiki/Starglider/Notes_On_Induction][more fargo critique]]

more FARGO related stuff 
SeekWell (cognition and analogy in musical realm) and SeqSee (cognition and analogy in number sequence domain)
http://singinst.org/summit/speakers/hofstadter/


comments on connectionist stuff
http://www.princeton.edu/~gdetre/notes/

comments on metacat
http://www.princeton.edu/~gdetre/notes/essay%20-%20curious%20machines,%20final%20paper%2010%20re-edit.htm

http://lesswrong.com/lw/ul/my_bayesian_enlightenment/

another link that describes more psych functions
http://www.acceleratingfuture.com/wiki/Cognitive_Science

Extracting Refined Rules from Knowledge-Based Neural Networks
http://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/

http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind

* Seekwell/Musicat??
http://seekwell.wordpress.com/
[[http://www.cs.indiana.edu/~epnichol/seekwell/][Description]]
[[http://singinst.org/summit/speakers/hofstadter/][REF]]

[[http://www.cs.indiana.edu/~epnichol/pages/resume.html][Authors website]]
[[http://www.capyblanca.com/search/label/fluid%20concepts][Link to general fluid concepts library?? linked from seekwell]]

* Seqsee
[[http://webcache.googleusercontent.com/search?q=cache:v453ggLDAekJ:cgi.cs.indiana.edu/~amahabal/pmwiki/pmwiki.php%3Fn%3DSeqsee.Seqsee+SeqSee&cd=2&hl=en&ct=clnk&gl=us&client=ubuntu&source=www.google.com][seqsee]]

[[http://amahabal.wordpress.com/][2006-wordpress]]

[[https://github.com/amahabal/Seqsee][Github code]]
[[sites.google.com/a/amahabal.com/main/files/Seqsee--doublesided.pdf][paper on it]]

* Introduction
Whenever starting a project, it is necessary to research what others have done.
While 'genetic algorithms' and 'neural networks' are commonly known among practically everyone to be associated with ai,
it is not commonly known that in the field of artificial general intelligence, focus has gone toward integrated cognitive 
architectures. This is also what psychology does - create computational cognitive models and then simulate.

Anyways, once the ideas have been found it is necessary to combine all relevant ones to bear on our cool problem!
Notice, that in dodo.org, I mention the need for a domain other than the big bad world to test our  agi (artificial general intelligence) in. This is quite
similar in spirit to the microdomains recommended by the Copycat/Tabletop architecture. Of course, other architectures
use test problems, but the the test problem is not a 'world' domain as we defined it - they dont allow exercising areas of
all aspects of cognition. Not that that's a bad thing - but in the end, one would like to exercise all aspects of cognition
but in a smaller world (but larger than the microdomains above, which actually test structural representation buildup). 

** Google Keywords
New terms you might want to google to get better results than 'genetic algoritihms' or neural nets! 
1. Deep belief networks
2. Cognitive Architecture
3. Artificial general intelligence (agi)
** Getting into the Game
Resources below have links to appropriate internet places. I particularly recommend accessing first (yes, in this order!)
1. Emotion Machine (Books)
2. Neurocomputing (Overview Paper)
3. [[http://science.slc.edu/~jmarshall/metacat/][Metacat]] and Fluid Concepts and Creative Analogies book

Also, pay attention to the organization section - this section contains a lot of papers that are referenced in this document - it
is basically a good place to discover new ideas. 
 
* Books
** /Emotion Machine/ and /Society of Mind/ 
Very nontechnical - but it gives you the right mentality for general intelligence. Contains numerous examples that
relate to real situations, and decomposing them into simpler elements. Read it first!
** /Principles of Synthetic Intelligence/ (MicroPSI/PSI architecture)
Book on MicroPSI/PSI Architecture
** /Fluid Concepts and Creative Analogies/
Book describing experiments with microdomains and creating structural representations from them. See Copycat in architecture below.
* Overview Papers
These papers give general overviews of current works.
** NeuroComputing - World Survey of Artificial brains, part II (2010)
An overview of three general types of neurcomputing architectures and some more in detail description of representative samples.
http://web.eecs.utk.edu/~itamar/Papers/NeuroComputing2010.pdf

* Architectures
** [[www.isd.mel.nist.gov/documents/albus/4DRCS_ver2.pdf][4DRCS]]
I havent read this, but abstract sounds interesting.

** [[http://www.icsi.berkeley.edu/~shastri/shruti/][Shruti]]
"We are capable of drawing a variety of inferences effortlessly, spontaneously, and with remarkable efficiency --- 
as though these inferences are a reflex response of our cognitive apparatus. This remarkable human ability poses a
 challenge for cognitive science and computational neuroscience: How can a system of slow neuron-like elements
 represent a large body of systematic knowledge and perform a wide range of inferences with such speed?

SHRUTI attempts to address this challenge by demonstrating how a connectionist network can encode a large body of semantic 
and episodic facts, systematic rule-like mappings, knowledge about entities, and types, and yet perform a wide range of
 reflexive inferences within a few hundred milliseconds."

The related paper is called
/From simple associations to systematic reasoning:a connectionist en-coding of rules, variables, and dynamic bindings using temporal synchrony/

** Copycat/Tabletop
Not an architecture per se, but each problem is  a microdomain in which a structural representation is stochastically
built of the problem (or something like that!). The idea is that, while other architectures encode representations which
the human programmer gives to it, a real ai architecture should be able to build its own representation of the situation.
A book on these various microdomains is /Fluid Concepts and Creative Analogies/

[[http://science.slc.edu/~jmarshall/metacat/][Metacat]]
http://www.cogsci.indiana.edu/microdomains.html
** [[www.aaai.org/ocs/index.php/FSS/FSS09/paper/download/951/1268][DESTIN]]
Created by [[http://mil.engr.utk.edu/nmil/member/2][AREL]]
it is a deep belief network for visual perception (right now). Current direction is to create quality open source
software - this is being pursued with opencog people (for example, see http://blog.opencog.org/2011/02/21/destin-vision-development/)
** SAL Integrated Architecture
Integrates [[http://grey.colorado.edu/emergent/index.php/Leabra][Leabra]] and [[http://act-r.psy.cmu.edu/][Act-R]] .
Leibr is a low level neuron implementation and act-r is more abstract. 
[[http://www.scribd.com/doc/31121092/DARPA-CognitiveResearch-II][DARPA contract summary - phase 1]]
** PSI/MicroPSI
Book on it:
Principles of Synthetic Intelligence

** AMBR/DUAL (partialy based on societ of mind)
http://alexpetrov.com/proj/

** Opencog
** [[http://mmp.mit.edu/][MMP]] initiative (core part is an architecture based on Emotion Machine)
*** About
[[http://web.mit.edu/newsoffice/2009/ai-overview-1207.html][MMP Article]]
*** [[http://web.media.mit.edu/~push/push-thesis.html][EM-ONE Thesis]]
*** Funk2
[[http://www.funk2.org/][Funk2]] is an open source programming language that has been created to make the Emotion Machine
architecture. It is a core part of the MMP. This work started by being based off of Push Singh's [[http://web.media.mit.edu/~push/push-thesis.html][EM-ONE Thesis]] in which
he implements a limited form of the Emotion Machine architecture in common lisp. A thesis
proposal for Funk2 is here [[http://docs.google.com/viewer?a=v&q=cache:IJPOxQF1dvAJ:neuromin.de/rct/morgan2010-a_computational_theory_of_the_communication_of_problem_solving_knowledge_between_parents_and_children.pdf+push+singh+em-one+code&hl=en&gl=us&pid=bl&srcid=ADGEESgR7BLxpluU3kNnMpeGPdcw9VRiq8_RzntV0H4i1QgtUB7D7vq-Mw721Gd1zmWZZeKLOFCJdqK2nbhhQ80oS1D4zDf_-4R78s8Uaf_i5gah33OO9Ed-qqbzHyuuMPLQ4orUSLrE&sig=AHIEtbSbAjz9K2KhyXLR6FdRKqxwrX1GNQ][Funk2 Thesis Proposal]].

[[https://github.com/bunuelo][Github Repository]]

* Organizations
** AAAI - Association for the Advancement of Artificial Intelligence
http://www.aaai.org/home.html
On this webesite, many papers can be found on AI, including many about architectures previously mentioned. 
"Founded in 1979, the Association for the Advancement of Artificial Intelligence (AAAI) (formerly the American Association 
for Artificial Intelligence) is a nonprofit scientific society devoted to advancing the 
scientific understanding of the mechanisms underlying thought and intelligent behavior and their 
embodiment in machines. AAAI also aims to increase public understanding of artificial intelligence, 
improve the teaching and training of AI practitioners, and provide guidance for research planners and 
funders concerning the importance and potential of current AI developments and future directions."

* Other Websites
http://www.adaptiveai.com/technology.html

http://ir.lib.sfu.ca/bitstream/1892/10815/1/etd4481.pdf

http://www.acceleratingfuture.com/people-blog/2008/cognitive-architectures-where-do-we-go-from-here/

http://neuromin.de/an/neuralmom.html

http://web.media.mit.edu/~minsky/papers/Internal%20Grounding.html

 

